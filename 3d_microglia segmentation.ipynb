{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Dataset: 3D ---\n",
      "Found 16 potential image directories for 3D.\n",
      "Finished loading 3D: 2236 total cells from 15 images.\n",
      "Value counts for Experimental_Group in 3D:\n",
      "Experimental_Group\n",
      "Assembled Together    1192\n",
      "Added Later           1044\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Loading Dataset: 2D ---\n",
      "Found 9 potential image directories for 2D.\n",
      "Finished loading 2D: 96 total cells from 9 images.\n",
      "Value counts for Experimental_Group in 2D:\n",
      "Experimental_Group\n",
      "3rd    38\n",
      "1st    31\n",
      "2nd    27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- (3D_per_cell) Exploratory Correlation Analysis ---\n",
      "Saved correlation heatmap: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/correlation_heatmap_3D_per_cell.pdf\n",
      "\n",
      "--- Running All Statistical Tests Upfront ---\n",
      "\n",
      "--- Applying Multiple Comparison Correction (Bonferroni) ---\n",
      "\n",
      "--- Generating All Plots with Corrected Significance ---\n",
      "--- (3D) Plotting True Num Endpoints ---\n",
      "Saved data to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/data_3D_true_num_endpoints.csv\n",
      "Saved figure to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/boxplot_3D_true_num_endpoints.pdf\n",
      "--- (3D) Plotting Sphericity ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5618/1832130961.py:360: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=agg_data, x='Experimental_Group', y=metric_col_name, order=box_plot_hue_order,\n",
      "/tmp/ipykernel_5618/1832130961.py:360: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=agg_data, x='Experimental_Group', y=metric_col_name, order=box_plot_hue_order,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/data_3D_sphericity.csv\n",
      "Saved figure to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/boxplot_3D_sphericity.pdf\n",
      "--- (3D) Plotting Skan Avg Branch Length µm ---\n",
      "Saved data to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/data_3D_skan_avg_branch_length_um.csv\n",
      "Saved figure to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/boxplot_3D_skan_avg_branch_length_um.pdf\n",
      "--- (3D) Plotting Shortest Distance µm ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5618/1832130961.py:360: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=agg_data, x='Experimental_Group', y=metric_col_name, order=box_plot_hue_order,\n",
      "/tmp/ipykernel_5618/1832130961.py:360: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=agg_data, x='Experimental_Group', y=metric_col_name, order=box_plot_hue_order,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/data_3D_shortest_distance_um.csv\n",
      "Saved figure to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/boxplot_3D_shortest_distance_um.pdf\n",
      "--- (3D) Plotting Num Cells ---\n",
      "Saved data to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/data_3D_num_cells.csv\n",
      "Saved figure to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_Analysis_by_Batch/boxplot_3D_num_cells.pdf\n",
      "--- (3D-Assembled_vs_2D) Plotting Shortest Distance µm ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5618/1832130961.py:360: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=agg_data, x='Experimental_Group', y=metric_col_name, order=box_plot_hue_order,\n",
      "/tmp/ipykernel_5618/1832130961.py:360: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(data=agg_data, x='Experimental_Group', y=metric_col_name, order=box_plot_hue_order,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_vs_2D_Comparison_by_Batch/data_3D-Assembled_vs_2D_shortest_distance_um.csv\n",
      "Saved figure to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/3D_vs_2D_Comparison_by_Batch/boxplot_3D-Assembled_vs_2D_shortest_distance_um.pdf\n",
      "\n",
      "--- Combined summary statistics (with correction) exported to: /home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined/summary_statistics_final_corrected.csv ---\n",
      "              Dataset                         Metric  \\\n",
      "0                  3D         Avg True Num Endpoints   \n",
      "1                  3D                 Avg Sphericity   \n",
      "2                  3D  Avg Skan Avg Branch Length µm   \n",
      "3                  3D       Avg Shortest Distance µm   \n",
      "4                  3D          Total Number of Cells   \n",
      "5  3D-Assembled_vs_2D       Avg Shortest Distance µm   \n",
      "\n",
      "                          Comparison    Test  Statistic   P_Value  \\\n",
      "0  Added Later vs Assembled Together  T-test     -0.414  0.705620   \n",
      "1  Added Later vs Assembled Together  T-test      0.687  0.529783   \n",
      "2  Added Later vs Assembled Together  T-test     -1.763  0.155241   \n",
      "3  Added Later vs Assembled Together  T-test     -0.529  0.638053   \n",
      "4  Added Later vs Assembled Together  T-test      0.255  0.819090   \n",
      "5        3D Assembled Together vs 2D  T-test    -31.427  0.000967   \n",
      "\n",
      "   P_Value_Corrected Significant_After_Correction  \n",
      "0           1.000000                        False  \n",
      "1           1.000000                        False  \n",
      "2           0.931445                        False  \n",
      "3           1.000000                        False  \n",
      "4           1.000000                        False  \n",
      "5           0.005799                         True  \n",
      "\n",
      "--- Main Analysis and Export Complete ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re # For regular expressions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "import colorsys\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_DIR_3D = '/home/kirill/Desktop/For_Kirill/Iba1_Morpho_BB_Blind (Copy)'\n",
    "GROUP_INFO_FILE_3D = '/home/kirill/Desktop/For_Kirill/iba1 Morpho_group.csv'\n",
    "METRICS_FILENAME_3D = 'metrics_df_ramified.csv'\n",
    "\n",
    "BASE_DIR_2D = '/home/kirill/Desktop/For_Kirill/microglial distance_2D_tiff (Copy)'\n",
    "METRICS_FILENAME_2D = 'metrics_df_ramified_2d.csv'\n",
    "\n",
    "EXPORT_BASE_DIRECTORY = '/home/kirill/Desktop/For_Kirill/Takeshi_analysis_combined'\n",
    "\n",
    "TITLE_FONTSIZE = 32\n",
    "AXIS_LABEL_FONTSIZE = 28\n",
    "TICK_LABEL_FONTSIZE = 24\n",
    "ANNOTATION_FONTSIZE = 20 # For \"n=...\" and p-values\n",
    "\n",
    "if not os.path.exists(EXPORT_BASE_DIRECTORY):\n",
    "    os.makedirs(EXPORT_BASE_DIRECTORY)\n",
    "    print(f\"Created base export directory: {EXPORT_BASE_DIRECTORY}\")\n",
    "\n",
    "ORIGINAL_CUSTOM_PALETTE = ['#00312F', '#1D2D46', '#46000D', '#5F3920', '#573844', '#424313', '#7A7A30', '#307A7A']\n",
    "BOXPLOT_WIDTH = 0.3  # Your preferred narrow width\n",
    "BOXPLOT_LINEWIDTH = 3.0 # Your preferred thick lines\n",
    "STRIPPLOT_JITTER = BOXPLOT_WIDTH * 0.4 # Jitter relative to the narrow box width (might need adjustment)\n",
    "STRIPPLOT_SIZE = 8 # Slightly smaller points for narrow boxes\n",
    "Y_AXIS_PADDING_FACTOR = 1 # Add 20% padding to the top of the y-axis\n",
    "all_stats_records = []\n",
    "\n",
    "# --- Helper Functions (make_pastel, format_axis_label, get_significance_asterisks, format_p_value_for_display) ---\n",
    "def make_pastel(hex_color, lightness_scale=0.7, saturation_scale=0.6):\n",
    "    try:\n",
    "        rgb_normalized = mcolors.to_rgb(hex_color)\n",
    "        h, l, s = colorsys.rgb_to_hls(rgb_normalized[0], rgb_normalized[1], rgb_normalized[2])\n",
    "        l_pastel = l + (1.0 - l) * lightness_scale; l_pastel = min(1.0, max(0.0, l_pastel))\n",
    "        s_pastel = s * saturation_scale; s_pastel = min(1.0, max(0.0, s_pastel))\n",
    "        rgb_pastel_normalized = colorsys.hls_to_rgb(h, l_pastel, s_pastel)\n",
    "        return mcolors.to_hex(rgb_pastel_normalized)\n",
    "    except ValueError: return hex_color\n",
    "\n",
    "def format_axis_label(label_text):\n",
    "    parts = label_text.split('_'); formatted_parts = []\n",
    "    for part in parts:\n",
    "        part_lower = part.lower()\n",
    "        if part_lower == \"um\": formatted_parts.append(\"µm\" + part[2:])\n",
    "        elif part_lower == \"um2\": formatted_parts.append(\"µm²\")\n",
    "        elif part_lower == \"um3\": formatted_parts.append(\"µm³\")\n",
    "        else: formatted_parts.append(part.capitalize())\n",
    "    return \" \".join(formatted_parts)\n",
    "\n",
    "def get_significance_asterisks(p_value):\n",
    "    if p_value is None: return \"\"\n",
    "    if p_value < 0.001: return \"***\"\n",
    "    if p_value < 0.01: return \"**\"\n",
    "    if p_value < 0.05: return \"*\"\n",
    "    return \"n.s.\"\n",
    "\n",
    "def format_p_value_for_display(p_value):\n",
    "    if p_value is None: return \"\"\n",
    "    sig = get_significance_asterisks(p_value)\n",
    "    if sig == \"n.s.\": return f\"n.s. (p={p_value:.3f})\"\n",
    "    if p_value < 0.001: return f\"p < 0.001{sig}\"\n",
    "    return f\"p={p_value:.3f}{sig}\"\n",
    "\n",
    "PASTEL_PALETTE = [make_pastel(color) for color in ORIGINAL_CUSTOM_PALETTE]\n",
    "# --- END Helper Functions ---\n",
    "\n",
    "# --- Data Loading and Processing Function ---\n",
    "def load_and_process_dataset(dataset_name_tag, base_dir, metrics_filename, \n",
    "                             image_dir_pattern_func,\n",
    "                             group_assignment_df_external=None, \n",
    "                             derive_group_from_image_id_func=None):\n",
    "    print(f\"\\n--- Loading Dataset: {dataset_name_tag} ---\")\n",
    "    all_metrics_data = []\n",
    "    if not os.path.isdir(base_dir):\n",
    "        print(f\"ERROR: Base directory '{base_dir}' for {dataset_name_tag} not found.\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        potential_dirs = os.listdir(base_dir)\n",
    "        image_id_dirs = sorted([d for d in potential_dirs if image_dir_pattern_func(d, base_dir)])\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not list or filter directories in '{base_dir}': {e}\")\n",
    "        return pd.DataFrame()\n",
    "    print(f\"Found {len(image_id_dirs)} potential image directories for {dataset_name_tag}.\")\n",
    "\n",
    "    for image_id in image_id_dirs:\n",
    "        processed_folder_name = f\"{image_id}_processed_{metrics_filename.replace('metrics_df_', '').replace('.csv', '')}\"\n",
    "        metrics_file_path = os.path.join(base_dir, image_id, processed_folder_name, metrics_filename)\n",
    "        \n",
    "        if os.path.exists(metrics_file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(metrics_file_path)\n",
    "                if df.empty: continue\n",
    "                df['Image_ID_Full'] = image_id \n",
    "                df['Dataset_Tag'] = dataset_name_tag\n",
    "                if derive_group_from_image_id_func:\n",
    "                    df['Experimental_Group'] = df['Image_ID_Full'].apply(derive_group_from_image_id_func)\n",
    "                all_metrics_data.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading metrics for {image_id} from {metrics_file_path}: {e}. Skipping.\")\n",
    "    if not all_metrics_data:\n",
    "        print(f\"No metrics data loaded for {dataset_name_tag}.\")\n",
    "        return pd.DataFrame()\n",
    "    dataset_df = pd.concat(all_metrics_data, ignore_index=True)\n",
    "    \n",
    "    if group_assignment_df_external is not None:\n",
    "        # This function now expects the group assignment df to have 'Image_ID', 'Experimental_Group', and 'Batch'\n",
    "        dataset_df['Image_ID_For_Merge'] = dataset_df['Image_ID_Full']\n",
    "        dataset_df = pd.merge(dataset_df, group_assignment_df_external, \n",
    "                              left_on='Image_ID_For_Merge', right_on='Image_ID',\n",
    "                              how='left', suffixes=('', '_external'))\n",
    "        \n",
    "        # Consolidate 'Experimental_Group' and 'Batch'\n",
    "        for col in ['Experimental_Group', 'Batch']:\n",
    "            external_col = f'{col}_external'\n",
    "            if external_col in dataset_df.columns:\n",
    "                if col not in dataset_df.columns:\n",
    "                    dataset_df[col] = dataset_df[external_col]\n",
    "                else:\n",
    "                    dataset_df[col] = np.where(dataset_df[external_col].notna(), \n",
    "                                               dataset_df[external_col], \n",
    "                                               dataset_df[col])\n",
    "                dataset_df.drop(columns=[external_col], inplace=True)\n",
    "\n",
    "        if 'Image_ID_For_Merge' in dataset_df.columns: dataset_df.drop(columns=['Image_ID_For_Merge'], inplace=True)\n",
    "        if 'Image_ID_y' in dataset_df.columns: dataset_df.drop(columns=['Image_ID_y'], inplace=True)\n",
    "        if 'Image_ID_x' in dataset_df.columns: dataset_df.rename(columns={'Image_ID_x':'Image_ID'}, inplace=True)\n",
    "\n",
    "    if 'Experimental_Group' not in dataset_df.columns or dataset_df['Experimental_Group'].isnull().all():\n",
    "        print(f\"Warning: No experimental groups assigned or derived for {dataset_name_tag}. Assigning 'DefaultGroup'.\")\n",
    "        dataset_df['Experimental_Group'] = f\"{dataset_name_tag}_DefaultGroup\"\n",
    "    \n",
    "    # Ensure Batch column exists, even if it's just a default\n",
    "    if 'Batch' not in dataset_df.columns:\n",
    "        dataset_df['Batch'] = dataset_df['Image_ID_Full'] # Each image is its own \"batch\" if no info\n",
    "\n",
    "    print(f\"Finished loading {dataset_name_tag}: {len(dataset_df)} total cells from {dataset_df['Image_ID_Full'].nunique()} images.\")\n",
    "    print(f\"Value counts for Experimental_Group in {dataset_name_tag}:\\n{dataset_df['Experimental_Group'].value_counts(dropna=False)}\")\n",
    "    return dataset_df\n",
    "\n",
    "def is_3d_image_dir(dir_name, base_path):\n",
    "    \"\"\"\n",
    "    Checks if a directory is a valid 3D image directory.\n",
    "    A directory is considered 3D if it contains a 'ramified_config.yaml' file\n",
    "    with a 'voxel_dimensions' key.\n",
    "    \"\"\"\n",
    "    # Assuming the config file is named 'ramified_config.yaml' and is at the top level of the image directory\n",
    "    config_file_path = os.path.join(base_path, dir_name, 'ramified_config.yaml')\n",
    "    \n",
    "    if not os.path.exists(config_file_path):\n",
    "        return False\n",
    "        \n",
    "    try:\n",
    "        with open(config_file_path, 'r') as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "        \n",
    "        # Check if config_data is a dictionary and contains the key\n",
    "        if isinstance(config_data, dict) and 'voxel_dimensions' in config_data:\n",
    "            return True\n",
    "            \n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Warning: Could not parse YAML file '{config_file_path}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error reading file '{config_file_path}': {e}\")\n",
    "        \n",
    "    return False\n",
    "\n",
    "def is_2d_image_dir(dir_name, base_path):\n",
    "    \"\"\"\n",
    "    Checks if a directory is a valid 2D image directory.\n",
    "    A directory is considered 2D if it contains a 'ramified_config.yaml' file\n",
    "    with a 'pixel_dimensions' key.\n",
    "    \"\"\"\n",
    "    # Assuming the config file is named 'ramified_config.yaml' for consistency\n",
    "    config_file_path = os.path.join(base_path, dir_name, 'ramified_config_2d.yaml')\n",
    "    \n",
    "    if not os.path.exists(config_file_path):\n",
    "        return False\n",
    "        \n",
    "    try:\n",
    "        with open(config_file_path, 'r') as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "\n",
    "        # Check if config_data is a dictionary and contains the key\n",
    "        if isinstance(config_data, dict) and 'pixel_dimensions' in config_data:\n",
    "            return True\n",
    "\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Warning: Could not parse YAML file '{config_file_path}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error reading file '{config_file_path}': {e}\")\n",
    "\n",
    "    return False\n",
    "\n",
    "def derive_2d_group(image_id_full):\n",
    "    \"\"\"Derives the batch ('1st', '2nd', etc.) from the 2D image filename.\"\"\"\n",
    "    # This regex now correctly finds the batch identifier like '1st', '2nd', '5th'\n",
    "    # from filenames like 'iba1-1st_5'\n",
    "    match = re.search(r\"iba1-(\\d+(?:st|nd|rd|th))\", image_id_full)\n",
    "    if match:\n",
    "        # We return the batch identifier, e.g., '1st', '2nd'. This will be our 'Experimental_Group'\n",
    "        # which acts as the biological replicate batch for 2D.\n",
    "        return match.group(1)\n",
    "    return \"2D_Other\" # Fallback\n",
    "\n",
    "# --- (CORRECTED) Central function to run all statistical tests upfront ---\n",
    "def run_all_statistics(metrics_to_test, agg_data, dataset_tag_str, valid_groups_list):\n",
    "    \"\"\"\n",
    "    Runs all statistical tests for a given dataset and returns a LIST of result dictionaries.\n",
    "    \"\"\"\n",
    "    # *** CHANGE: Initialize as a list, not a dictionary ***\n",
    "    stats_records = []\n",
    "    \n",
    "    if agg_data.empty:\n",
    "        return stats_records\n",
    "\n",
    "    for metric_col_name in metrics_to_test:\n",
    "        if metric_col_name not in agg_data.columns:\n",
    "            continue\n",
    "\n",
    "        p_val = None\n",
    "        s_stat = None\n",
    "        test_type = 'None'\n",
    "        comparison_str = 'N/A'\n",
    "        \n",
    "        # Determine the formatted metric name here for consistency\n",
    "        formatted_metric_name = \"Total Number of Cells\" if metric_col_name == 'num_cells' else f\"Avg {format_axis_label(metric_col_name)}\"\n",
    "\n",
    "        if len(valid_groups_list) == 2:\n",
    "            g1n, g2n = valid_groups_list[0], valid_groups_list[1]\n",
    "            g1d = agg_data[agg_data['Experimental_Group'] == g1n][metric_col_name].dropna()\n",
    "            g2d = agg_data[agg_data['Experimental_Group'] == g2n][metric_col_name].dropna()\n",
    "            if len(g1d) >= 2 and len(g2d) >= 2:\n",
    "                s_stat, p_val = ttest_ind(g1d, g2d, nan_policy='omit', equal_var=False)\n",
    "                test_type = 'T-test'\n",
    "                comparison_str = f\"{g1n} vs {g2n}\"\n",
    "        \n",
    "        elif len(valid_groups_list) > 2:\n",
    "            samples_anova = [d[metric_col_name].dropna() for _, d in agg_data[agg_data['Experimental_Group'].isin(valid_groups_list)].groupby('Experimental_Group')]\n",
    "            valid_samples_anova = [s for s in samples_anova if len(s) >= 2]\n",
    "            if len(valid_samples_anova) == len(agg_data[agg_data['Experimental_Group'].isin(valid_groups_list)]['Experimental_Group'].unique()):\n",
    "                s_stat, p_val = f_oneway(*valid_samples_anova)\n",
    "                test_type = 'ANOVA'\n",
    "                comparison_str = f\"Across {len(valid_groups_list)} groups\"\n",
    "\n",
    "        if p_val is not None:\n",
    "            # *** CHANGE: Append a dictionary to the list ***\n",
    "            stats_records.append({\n",
    "                'Dataset': dataset_tag_str,\n",
    "                'Metric': formatted_metric_name, # Use the consistent formatted name\n",
    "                'Raw_Metric': metric_col_name, # Store the raw metric name for easier lookup\n",
    "                'Comparison': comparison_str,\n",
    "                'Test': test_type,\n",
    "                'Statistic': f\"{s_stat:.3f}\",\n",
    "                'P_Value': p_val, # Store the raw p-value\n",
    "            })\n",
    "            \n",
    "    return stats_records\n",
    "\n",
    "# --- (NEW) Helper function for correlation heatmaps ---\n",
    "def plot_correlation_heatmap(df, metrics_list, dataset_tag_str, export_directory_path):\n",
    "    \"\"\"Calculates and plots a correlation heatmap for a given list of metrics.\"\"\"\n",
    "    print(f\"\\n--- ({dataset_tag_str}) Exploratory Correlation Analysis ---\")\n",
    "    \n",
    "    # Select only the metrics that exist in the dataframe\n",
    "    metrics_to_correlate = [m for m in metrics_list if m in df.columns]\n",
    "    if len(metrics_to_correlate) < 2:\n",
    "        print(\"Not enough metrics to create a correlation heatmap.\")\n",
    "        return\n",
    "        \n",
    "    correlation_matrix = df[metrics_to_correlate].corr()\n",
    "    \n",
    "    # Create formatted labels for the heatmap\n",
    "    formatted_labels = [format_axis_label(m) for m in metrics_to_correlate]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        correlation_matrix, \n",
    "        annot=True,          # Show the correlation values\n",
    "        fmt=\".2f\",           # Format to 2 decimal places\n",
    "        cmap='coolwarm',     # Use a diverging colormap\n",
    "        linewidths=.5,\n",
    "        ax=ax,\n",
    "        xticklabels=formatted_labels,\n",
    "        yticklabels=formatted_labels\n",
    "    )\n",
    "    ax.set_title(f'({dataset_tag_str}) Correlation Matrix of Morphological Metrics')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    pdf_path = os.path.join(export_directory_path, f'correlation_heatmap_{dataset_tag_str}.pdf')\n",
    "    plt.savefig(pdf_path, format='pdf', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved correlation heatmap: {pdf_path}\")\n",
    "\n",
    "def plot_metric_boxplot(metric_col_name, data_df_source, dataset_tag_str, plot_title_suffix, \n",
    "                        export_directory_path, \n",
    "                        valid_groups_list, palette_map_orig_func, palette_map_pastel_func,\n",
    "                        raw_p_value=None, corrected_p_value=None,\n",
    "                        y_label_override=None, is_pre_aggregated=False):\n",
    "\n",
    "    # Generate palettes based on the specific valid_groups_list for this plot\n",
    "    palette_map_orig = palette_map_orig_func(valid_groups_list)\n",
    "    palette_map_pastel = palette_map_pastel_func(valid_groups_list)\n",
    "\n",
    "    print(f\"--- ({dataset_tag_str}) Plotting {format_axis_label(metric_col_name)} ---\")\n",
    "    \n",
    "    if metric_col_name not in data_df_source.columns or not valid_groups_list:\n",
    "        print(f\"Skipping plot for {format_axis_label(metric_col_name)} in {dataset_tag_str}: column missing or no valid groups.\")\n",
    "        return\n",
    "\n",
    "    # Boxplot\n",
    "    if is_pre_aggregated:\n",
    "        agg_data = data_df_source.copy()\n",
    "        if 'Comparison_Group' in agg_data.columns and 'Experimental_Group' not in agg_data.columns:\n",
    "            agg_data = agg_data.rename(columns={'Comparison_Group': 'Experimental_Group'})\n",
    "        elif 'Comparison_Group' in agg_data.columns and 'Experimental_Group' in agg_data.columns:\n",
    "            if agg_data['Experimental_Group'].isnull().all() and not agg_data['Comparison_Group'].isnull().all():\n",
    "                agg_data.drop(columns=['Experimental_Group'], inplace=True)\n",
    "                agg_data.rename(columns={'Comparison_Group': 'Experimental_Group'}, inplace=True)\n",
    "    else:\n",
    "        id_col_for_agg = 'Image_ID_Full' if 'Image_ID_Full' in data_df_source.columns else 'Image_ID'\n",
    "        if id_col_for_agg not in data_df_source.columns or 'Experimental_Group' not in data_df_source.columns:\n",
    "             print(f\"ERROR: Cannot aggregate for boxplot {metric_col_name} in {dataset_tag_str}, missing ID or Group column.\")\n",
    "             return\n",
    "        agg_data = data_df_source.groupby([id_col_for_agg, 'Experimental_Group'])[metric_col_name].mean().reset_index()\n",
    "    \n",
    "    agg_data = agg_data.dropna(subset=['Experimental_Group', metric_col_name])\n",
    "    if agg_data.empty:\n",
    "        print(f\"No aggregated data to plot for {metric_col_name} in {dataset_tag_str}.\")\n",
    "        return\n",
    "        \n",
    "    n_counts = agg_data['Experimental_Group'].value_counts().reindex(valid_groups_list).fillna(0).astype(int)\n",
    "\n",
    "    # Dynamic figure width for boxplots\n",
    "    num_groups = len(valid_groups_list)\n",
    "    if num_groups <= 3:\n",
    "        fig_width = max(8, num_groups * 1.5)\n",
    "    elif num_groups <=5:\n",
    "        fig_width = num_groups * 1.2\n",
    "    else:\n",
    "        fig_width = num_groups * 1.0\n",
    "    fig_width = min(fig_width, 12)\n",
    "\n",
    "    fig_box, ax_box = plt.subplots(figsize=(fig_width, 6))\n",
    "    \n",
    "    box_plot_hue_order = [g for g in valid_groups_list if g in palette_map_pastel]\n",
    "    if not box_plot_hue_order and valid_groups_list: box_plot_hue_order = valid_groups_list\n",
    "\n",
    "    sns.boxplot(data=agg_data, x='Experimental_Group', y=metric_col_name, order=box_plot_hue_order, \n",
    "                palette={g: palette_map_pastel.get(g, '#dddddd') for g in box_plot_hue_order}, \n",
    "                showfliers=False, width=BOXPLOT_WIDTH, linewidth=BOXPLOT_LINEWIDTH, ax=ax_box)\n",
    "    \n",
    "    for g_name_plot in box_plot_hue_order:\n",
    "        current_g_data_plot = agg_data[agg_data['Experimental_Group'] == g_name_plot]\n",
    "        if not current_g_data_plot.empty:\n",
    "            sns.stripplot(data=current_g_data_plot, x='Experimental_Group', y=metric_col_name, \n",
    "                          order=box_plot_hue_order, \n",
    "                          color=palette_map_orig.get(g_name_plot, '#333333'), \n",
    "                          alpha=0.9, jitter=STRIPPLOT_JITTER, size=STRIPPLOT_SIZE, ax=ax_box, dodge=False)\n",
    "    \n",
    "    y_max_overall = agg_data[metric_col_name].max() if not agg_data[metric_col_name].empty else 0\n",
    "    min_overall_data = agg_data[metric_col_name].min() if not agg_data[metric_col_name].empty else 0\n",
    "    max_n_text_y = -np.inf\n",
    "\n",
    "    for i, g_name_text in enumerate(box_plot_hue_order):\n",
    "        n_val = n_counts.get(g_name_text, 0)\n",
    "        g_points = agg_data[agg_data['Experimental_Group'] == g_name_text][metric_col_name]\n",
    "        text_y_val = y_max_overall * 1.02\n",
    "        if not g_points.empty:\n",
    "            q75 = g_points.quantile(0.75); iqr = q75 - g_points.quantile(0.25)\n",
    "            upper_w = q75 + 1.5 * iqr if iqr > 0 else q75\n",
    "            max_strip = g_points.max() if not g_points.empty else q75\n",
    "            text_y_val = max(upper_w, max_strip) * 1.05 \n",
    "            if text_y_val == 0 and y_max_overall == 0: text_y_val = 0.05 * (abs(min_overall_data) if min_overall_data !=0 else 1)\n",
    "        elif y_max_overall == 0: text_y_val = 0.05 * (abs(min_overall_data) if min_overall_data !=0 else 1)\n",
    "        \n",
    "        ax_box.text(i, text_y_val, f\"n={n_val}\", ha='center', va='bottom', fontsize=ANNOTATION_FONTSIZE)\n",
    "        max_n_text_y = max(max_n_text_y, text_y_val if text_y_val is not None else -np.inf)\n",
    "\n",
    "    ax_box.set_title(f'({dataset_tag_str}) Avg {format_axis_label(metric_col_name)} {plot_title_suffix}', fontsize=TITLE_FONTSIZE)\n",
    "    ax_box.set_xlabel('', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "    ax_box.set_ylabel(y_label_override if y_label_override else f'Avg {format_axis_label(metric_col_name)}', fontsize=AXIS_LABEL_FONTSIZE)\n",
    "    \n",
    "    ax_box.tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONTSIZE)\n",
    "    \n",
    "    y_lim_top = max_n_text_y * 1.05 if max_n_text_y > -np.inf else y_max_overall * 1.1 \n",
    "    if y_lim_top <= 0 : y_lim_top = (y_max_overall if y_max_overall > 0 else 1) * 1.1\n",
    "\n",
    "    if corrected_p_value is not None and len(box_plot_hue_order) == 2:\n",
    "        g1n, g2n = box_plot_hue_order[0], box_plot_hue_order[1]\n",
    "        g1d = agg_data[agg_data['Experimental_Group'] == g1n][metric_col_name].dropna()\n",
    "        g2d = agg_data[agg_data['Experimental_Group'] == g2n][metric_col_name].dropna()\n",
    "        display_text = format_p_value_for_display(corrected_p_value)\n",
    "        \n",
    "        current_max_data_for_bar = max(g1d.max() if not g1d.empty else 0, g2d.max() if not g2d.empty else 0)\n",
    "        y_bar_start_ref = max_n_text_y if max_n_text_y > -np.inf else current_max_data_for_bar\n",
    "        y_bar = y_bar_start_ref * 1.08 \n",
    "        y_bar = max(y_bar, current_max_data_for_bar * 1.15) \n",
    "        if y_bar <= 0: y_bar = (current_max_data_for_bar if current_max_data_for_bar > 0 else 1) * 1.15\n",
    "\n",
    "        t_level = y_bar * 1.05 \n",
    "        if t_level <= 0: t_level = y_bar + (abs(y_bar) * 0.05 if y_bar != 0 else 0.05)\n",
    "\n",
    "        tick_h_abs = (y_bar - (max_n_text_y if max_n_text_y > -np.inf and max_n_text_y > 0 else y_bar*0.9)) * 0.1 \n",
    "        if tick_h_abs <= 0: tick_h_abs = y_bar * 0.02 if y_bar != 0 else 0.002\n",
    "        \n",
    "        ax_box.plot([0,1],[y_bar,y_bar],lw=1.5,c='k'); \n",
    "        ax_box.plot([0,0],[y_bar-tick_h_abs,y_bar],lw=1.5,c='k'); \n",
    "        ax_box.plot([1,1],[y_bar-tick_h_abs,y_bar],lw=1.5,c='k')\n",
    "        ax_box.text(0.5, t_level, display_text, ha='center', va='bottom', fontsize=ANNOTATION_FONTSIZE)\n",
    "        y_lim_top = max(y_lim_top, t_level * 1.05) if t_level is not None else y_lim_top\n",
    "\n",
    "    _, current_ylim_t = ax_box.get_ylim()\n",
    "    bottom_limit = 0\n",
    "    if min_overall_data < 0:\n",
    "        bottom_limit = min_overall_data * 1.1\n",
    "    \n",
    "    new_top_limit = max(current_ylim_t, y_lim_top) * Y_AXIS_PADDING_FACTOR\n",
    "    \n",
    "    if new_top_limit <= bottom_limit:\n",
    "        new_top_limit = bottom_limit + (abs(bottom_limit) * 0.1 if bottom_limit != 0 else 0.1)\n",
    "    \n",
    "    ax_box.set_ylim(bottom=bottom_limit, top=new_top_limit)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # --- CHANGE HERE: Export only the relevant columns to CSV ---\n",
    "    # Define the columns that are essential for this plot\n",
    "    # The group column is always 'Experimental_Group' at this stage\n",
    "    # The metric column is metric_col_name\n",
    "    # We also might want to include the original biological replicate identifier\n",
    "    export_cols = ['Experimental_Group', metric_col_name]\n",
    "    \n",
    "    # Check if a replicate ID column like 'Batch' exists and add it for context\n",
    "    if 'Batch' in agg_data.columns:\n",
    "        export_cols.insert(0, 'Batch') # Add 'Batch' to the beginning if it exists\n",
    "    \n",
    "    # Filter the dataframe to only include these columns for export\n",
    "    df_to_export = agg_data[export_cols]\n",
    "\n",
    "    csv_path_box = os.path.join(export_directory_path, f'data_{dataset_tag_str}_{metric_col_name}.csv')\n",
    "    df_to_export.to_csv(csv_path_box, index=False, float_format='%.5g') # Using .5g for good precision\n",
    "    print(f\"Saved data to: {csv_path_box}\")\n",
    "    # --- END OF CHANGE ---\n",
    "\n",
    "    # Export Figure to PDF\n",
    "    pdf_path_box = os.path.join(export_directory_path, f'boxplot_{dataset_tag_str}_{metric_col_name}.pdf')\n",
    "    plt.savefig(pdf_path_box, format='pdf', bbox_inches='tight'); plt.close(fig_box)\n",
    "    print(f\"Saved figure to: {pdf_path_box}\")\n",
    "\n",
    "# --- Palette generation functions (to pass to plotting function) ---\n",
    "def get_original_palette(groups):\n",
    "    return {g: ORIGINAL_CUSTOM_PALETTE[i % len(ORIGINAL_CUSTOM_PALETTE)] for i, g in enumerate(groups)}\n",
    "def get_pastel_palette(groups):\n",
    "    return {g: PASTEL_PALETTE[i % len(PASTEL_PALETTE)] for i, g in enumerate(groups)}\n",
    "\n",
    "# --- Main Analysis Script ---\n",
    "# 1. Load 3D Data\n",
    "group_df_3d = None\n",
    "try:\n",
    "    group_df_raw_3d = pd.read_csv(GROUP_INFO_FILE_3D)\n",
    "    group_df_raw_3d = group_df_raw_3d.rename(columns={'Unnamed: 0': 'Batch'})\n",
    "    group_name_map = {'Group1': 'Assembled Together', 'Group2': 'Added Later'}\n",
    "    melted_dfs = []\n",
    "    for group_col_name, desc_group_name in group_name_map.items():\n",
    "        group_subset = group_df_raw_3d[['Batch', group_col_name]].dropna(subset=[group_col_name])\n",
    "        group_subset = group_subset.rename(columns={group_col_name: 'Image_ID'})\n",
    "        group_subset['Experimental_Group'] = desc_group_name\n",
    "        melted_dfs.append(group_subset)\n",
    "    group_df_3d = pd.concat(melted_dfs, ignore_index=True)\n",
    "    group_df_3d['Image_ID'] = group_df_3d['Image_ID'].astype(str).str.strip()\n",
    "except Exception as e_3d_group:\n",
    "    print(f\"Warning: Could not load or process 3D group assignments from '{GROUP_INFO_FILE_3D}': {e_3d_group}\")\n",
    "\n",
    "data_3d_df = load_and_process_dataset(\"3D\", BASE_DIR_3D, METRICS_FILENAME_3D, is_3d_image_dir, group_assignment_df_external=group_df_3d)\n",
    "\n",
    "# 2. Load 2D Data (for comparison purposes only)\n",
    "data_2d_df = load_and_process_dataset(\"2D\", BASE_DIR_2D, METRICS_FILENAME_2D, is_2d_image_dir, derive_group_from_image_id_func=derive_2d_group)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# NEW WORKFLOW: Define tasks, run all stats, correct, then plot all.\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "analysis_tasks = []\n",
    "all_raw_stats_records = []\n",
    "\n",
    "# --- Task 1: 3D Standalone Analysis ---\n",
    "if not data_3d_df.empty:\n",
    "    export_dir_3d = os.path.join(EXPORT_BASE_DIRECTORY, \"3D_Analysis_by_Batch\")\n",
    "    if not os.path.exists(export_dir_3d): os.makedirs(export_dir_3d)\n",
    "    \n",
    "    all_3d_metrics_for_corr = ['shortest_distance_um', 'true_num_branches', 'skan_total_length_um', 'skan_avg_branch_length_um', 'true_num_junctions', 'true_num_endpoints', 'sphericity', 'volume_um3']\n",
    "    plot_correlation_heatmap(data_3d_df, all_3d_metrics_for_corr, \"3D_per_cell\", export_dir_3d)\n",
    "    \n",
    "    image_level_avg_3d = data_3d_df.groupby(['Image_ID_Full', 'Experimental_Group', 'Batch']).mean(numeric_only=True).reset_index()\n",
    "    biological_replicate_avg_3d = image_level_avg_3d.groupby(['Batch', 'Experimental_Group']).mean(numeric_only=True).reset_index()\n",
    "    valid_groups_3d = sorted(biological_replicate_avg_3d['Experimental_Group'].dropna().unique())\n",
    "    \n",
    "    cells_per_image_3d = data_3d_df.groupby(['Image_ID_Full', 'Experimental_Group', 'Batch']).size().reset_index(name='num_cells')\n",
    "    cells_per_batch_3d = cells_per_image_3d.groupby(['Batch', 'Experimental_Group'])['num_cells'].mean().reset_index()\n",
    "    bio_reps_3d_with_counts = pd.merge(biological_replicate_avg_3d, cells_per_batch_3d, on=['Batch', 'Experimental_Group'])\n",
    "    \n",
    "    metrics_3d_pruned = [\n",
    "        'true_num_endpoints',          # Mandatory representative for ramification\n",
    "        'sphericity',                # Independent shape metric\n",
    "        'skan_avg_branch_length_um', # Independent branch quality metric\n",
    "        'shortest_distance_um'       # Independent extrinsic metric\n",
    "    ]\n",
    "    \n",
    "    analysis_tasks.append({\n",
    "        \"dataset_tag\": \"3D\",\n",
    "        \"export_dir\": export_dir_3d,\n",
    "        \"metrics_to_test\": metrics_3d_pruned + ['num_cells'],\n",
    "        \"agg_data\": bio_reps_3d_with_counts,\n",
    "        \"valid_groups\": valid_groups_3d\n",
    "    })\n",
    "\n",
    "# --- Task 2: 3D vs 2D Comparison ---\n",
    "# This task defines the *only* analysis where 2D data is used.\n",
    "if 'biological_replicate_avg_3d' in locals() and not biological_replicate_avg_3d.empty and not data_2d_df.empty and 'Assembled Together' in data_3d_df['Experimental_Group'].unique():\n",
    "    \n",
    "    # Prep 3D data for comparison\n",
    "    data_3d_g1_reps = biological_replicate_avg_3d[biological_replicate_avg_3d['Experimental_Group'] == 'Assembled Together'].copy()\n",
    "    data_3d_g1_reps['Comparison_Group'] = '3D Assembled Together'\n",
    "    \n",
    "    # Aggregate 2D data to the biological replicate level *only for this task*\n",
    "    image_level_avg_2d = data_2d_df.groupby(['Image_ID_Full', 'Experimental_Group']).mean(numeric_only=True).reset_index()\n",
    "    biological_replicate_avg_2d = image_level_avg_2d.groupby('Experimental_Group').mean(numeric_only=True).reset_index()\n",
    "    data_2d_all_reps = biological_replicate_avg_2d.copy()\n",
    "    data_2d_all_reps['Comparison_Group'] = '2D'\n",
    "\n",
    "    # Combine data for the specific metric\n",
    "    comparison_df = pd.concat([\n",
    "        data_3d_g1_reps[['shortest_distance_um', 'Comparison_Group']],\n",
    "        data_2d_all_reps[['shortest_distance_um', 'Comparison_Group']]\n",
    "    ], ignore_index=True).rename(columns={'Comparison_Group': 'Experimental_Group'})\n",
    "\n",
    "    # Add the comparison analysis as a task\n",
    "    analysis_tasks.append({\n",
    "        \"dataset_tag\": \"3D-Assembled_vs_2D\",\n",
    "        \"export_dir\": os.path.join(EXPORT_BASE_DIRECTORY, \"3D_vs_2D_Comparison_by_Batch\"),\n",
    "        \"metrics_to_test\": ['shortest_distance_um'],\n",
    "        \"agg_data\": comparison_df,\n",
    "        \"valid_groups\": ['3D Assembled Together', '2D']\n",
    "    })\n",
    "\n",
    "# --- Run All Statistics, Apply Correction, Plot, and Export ---\n",
    "print(\"\\n--- Running All Statistical Tests Upfront ---\")\n",
    "for task in analysis_tasks:\n",
    "    task_stats_records = run_all_statistics(\n",
    "        metrics_to_test=task['metrics_to_test'],\n",
    "        agg_data=task['agg_data'],\n",
    "        dataset_tag_str=task['dataset_tag'],\n",
    "        valid_groups_list=task['valid_groups']\n",
    "    )\n",
    "    all_raw_stats_records.extend(task_stats_records)\n",
    "\n",
    "if all_raw_stats_records:\n",
    "    stats_df = pd.DataFrame(all_raw_stats_records)\n",
    "    p_values_to_correct = stats_df['P_Value'].dropna()\n",
    "    \n",
    "    if not p_values_to_correct.empty:\n",
    "        print(\"\\n--- Applying Multiple Comparison Correction (Bonferroni) ---\")\n",
    "        from statsmodels.stats.multitest import multipletests\n",
    "        reject, pvals_corrected, _, _ = multipletests(p_values_to_correct, alpha=0.05, method='bonferroni')\n",
    "        \n",
    "        stats_df.loc[p_values_to_correct.index, 'P_Value_Corrected'] = pvals_corrected\n",
    "        stats_df.loc[p_values_to_correct.index, 'Significant_After_Correction'] = reject\n",
    "    else:\n",
    "        print(\"No valid p-values found to correct.\")\n",
    "else:\n",
    "    stats_df = pd.DataFrame()\n",
    "\n",
    "print(\"\\n--- Generating All Plots with Corrected Significance ---\")\n",
    "for task in analysis_tasks:\n",
    "    if not os.path.exists(task['export_dir']): os.makedirs(task['export_dir'])\n",
    "    \n",
    "    for metric in task['metrics_to_test']:\n",
    "        if metric in task['agg_data'].columns:\n",
    "            \n",
    "            stat_row = stats_df[\n",
    "                (stats_df['Dataset'] == task['dataset_tag']) &\n",
    "                (stats_df['Raw_Metric'] == metric)\n",
    "            ]\n",
    "            \n",
    "            raw_p = None\n",
    "            corr_p = None\n",
    "            if not stat_row.empty:\n",
    "                raw_p = stat_row.iloc[0].get('P_Value')\n",
    "                corr_p = stat_row.iloc[0].get('P_Value_Corrected')\n",
    "            \n",
    "            y_label = \"Total Number of Cells\" if metric == 'num_cells' else None\n",
    "            \n",
    "            plot_metric_boxplot(\n",
    "                metric_col_name=metric,\n",
    "                data_df_source=task['agg_data'],\n",
    "                dataset_tag_str=task['dataset_tag'],\n",
    "                plot_title_suffix=\"per Biological Replicate\",\n",
    "                export_directory_path=task['export_dir'],\n",
    "                valid_groups_list=task['valid_groups'],\n",
    "                palette_map_orig_func=get_original_palette,\n",
    "                palette_map_pastel_func=get_pastel_palette,\n",
    "                raw_p_value=raw_p,\n",
    "                corrected_p_value=corr_p,\n",
    "                y_label_override=y_label,\n",
    "                is_pre_aggregated=True\n",
    "            )\n",
    "\n",
    "# --- Export Final Statistics Table ---\n",
    "if not stats_df.empty:\n",
    "    for col in ['P_Value', 'Statistic', 'P_Value_Corrected']:\n",
    "        if col in stats_df.columns:\n",
    "            stats_df[col] = pd.to_numeric(stats_df[col], errors='coerce')\n",
    "\n",
    "    stats_csv_path = os.path.join(EXPORT_BASE_DIRECTORY, 'summary_statistics_final_corrected.csv')\n",
    "    \n",
    "    final_cols = ['Dataset', 'Metric', 'Comparison', 'Test', 'Statistic', 'P_Value', 'P_Value_Corrected', 'Significant_After_Correction']\n",
    "    final_cols_exist = [col for col in final_cols if col in stats_df.columns]\n",
    "    \n",
    "    stats_df[final_cols_exist].to_csv(stats_csv_path, index=False, float_format='%.4g')\n",
    "    print(f\"\\n--- Combined summary statistics (with correction) exported to: {stats_csv_path} ---\")\n",
    "    print(stats_df[final_cols_exist])\n",
    "else:\n",
    "    print(\"\\n--- No statistical tests were performed or recorded. ---\")\n",
    "\n",
    "print(\"\\n--- Main Analysis and Export Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dsegment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
